{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering with Sklearn - Descrição da Tarefa\n",
        "\n",
        "\n",
        "Baixe os três conjuntos de dados. Cada um deles possui características de atributos distintas. Utilizando técnicas de engenharia de atributos com sklearn (ou outra ferramenta), selecione a menor quantidade de atributos possível em cada um deles, mas sem remover atributos significativos."
      ],
      "metadata": {
        "id": "v-wtnYmzWS3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Datasets"
      ],
      "metadata": {
        "id": "YsOH5j5Tv-eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -qqq"
      ],
      "metadata": {
        "id": "aS1GWYZ9sBxS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1q_VpqJ8O8JazQez-N6SYTBb51T4QrpMz\n",
        "!gdown https://drive.google.com/uc?id=1tFcc2B7UfIzy7q3P49EzVxgetdRnbxfc\n",
        "!gdown https://drive.google.com/uc?id=13fGg8YT844EN3xLgl5UzW1HOsOIbqYPo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqPQDrM4sJd4",
        "outputId": "626dd4f3-ffef-4437-84f9-5247e6575a89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q_VpqJ8O8JazQez-N6SYTBb51T4QrpMz\n",
            "To: /content/ia_fe_dataset1.csv\n",
            "100% 161k/161k [00:00<00:00, 68.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tFcc2B7UfIzy7q3P49EzVxgetdRnbxfc\n",
            "To: /content/ia_fe_dataset2.csv\n",
            "100% 1.55M/1.55M [00:00<00:00, 90.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13fGg8YT844EN3xLgl5UzW1HOsOIbqYPo\n",
            "To: /content/ia_fe_dataset3.csv\n",
            "100% 3.08M/3.08M [00:00<00:00, 138MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Armazenanando os dados dos arquivos csv disponibilizados nas seguintes váriaveis:"
      ],
      "metadata": {
        "id": "lm0l7HMV22ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('/content/ia_fe_dataset1.csv')\n",
        "df2 = pd.read_csv('/content/ia_fe_dataset2.csv')\n",
        "df3 = pd.read_csv('/content/ia_fe_dataset3.csv')"
      ],
      "metadata": {
        "id": "XpQ2P1C-2kYJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Selection\n",
        "\n",
        "### Explanation: https://www.w3schools.com/python/pandas/pandas_correlations.asp\n",
        "### Reference Guide: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n",
        "### Source: https://github.com/pandas-dev/pandas/blob/v2.2.2/pandas/core/frame.py#L10975-L11087\n"
      ],
      "metadata": {
        "id": "c_Lr4XQsqMob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seleção de features ajuda a identificar as informações mais relevantes em um conjunto de dados. Uma maneira de fazer isso é a remoção de features com alta correlação. Desta forma podemos calcular a correlação do dataset 1:"
      ],
      "metadata": {
        "id": "qae5CdUAGlm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.corr().style.background_gradient(cmap='coolwarm')"
      ],
      "metadata": {
        "id": "osAC8p5MvWVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "07abe8c6-9179-4783-c69a-19e4aa10b462"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7dd54c814970>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_cce50_row0_col0, #T_cce50_row1_col1, #T_cce50_row1_col2, #T_cce50_row2_col1, #T_cce50_row2_col2, #T_cce50_row3_col3, #T_cce50_row4_col4, #T_cce50_row5_col5 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cce50_row0_col1, #T_cce50_row0_col2 {\n",
              "  background-color: #5a78e4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cce50_row0_col3, #T_cce50_row3_col0 {\n",
              "  background-color: #b70d28;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cce50_row0_col4, #T_cce50_row3_col4, #T_cce50_row3_col5 {\n",
              "  background-color: #3e51c5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cce50_row0_col5, #T_cce50_row1_col4, #T_cce50_row2_col4, #T_cce50_row4_col1, #T_cce50_row4_col2, #T_cce50_row5_col0, #T_cce50_row5_col3 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cce50_row1_col0, #T_cce50_row2_col0 {\n",
              "  background-color: #cfdaea;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_cce50_row1_col3, #T_cce50_row2_col3 {\n",
              "  background-color: #e8d6cc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_cce50_row1_col5, #T_cce50_row2_col5 {\n",
              "  background-color: #c1d4f4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_cce50_row3_col1, #T_cce50_row3_col2 {\n",
              "  background-color: #93b5fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_cce50_row4_col0 {\n",
              "  background-color: #bfd3f6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_cce50_row4_col3 {\n",
              "  background-color: #bcd2f7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_cce50_row4_col5 {\n",
              "  background-color: #c0d4f5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_cce50_row5_col1, #T_cce50_row5_col2 {\n",
              "  background-color: #4358cb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cce50_row5_col4 {\n",
              "  background-color: #4055c8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_cce50\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_cce50_level0_col0\" class=\"col_heading level0 col0\" >feature_1</th>\n",
              "      <th id=\"T_cce50_level0_col1\" class=\"col_heading level0 col1\" >feature_2</th>\n",
              "      <th id=\"T_cce50_level0_col2\" class=\"col_heading level0 col2\" >feature_3</th>\n",
              "      <th id=\"T_cce50_level0_col3\" class=\"col_heading level0 col3\" >feature_4</th>\n",
              "      <th id=\"T_cce50_level0_col4\" class=\"col_heading level0 col4\" >feature_5</th>\n",
              "      <th id=\"T_cce50_level0_col5\" class=\"col_heading level0 col5\" >target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_cce50_level0_row0\" class=\"row_heading level0 row0\" >feature_1</th>\n",
              "      <td id=\"T_cce50_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
              "      <td id=\"T_cce50_row0_col1\" class=\"data row0 col1\" >0.088525</td>\n",
              "      <td id=\"T_cce50_row0_col2\" class=\"data row0 col2\" >0.088525</td>\n",
              "      <td id=\"T_cce50_row0_col3\" class=\"data row0 col3\" >0.985768</td>\n",
              "      <td id=\"T_cce50_row0_col4\" class=\"data row0 col4\" >-0.002907</td>\n",
              "      <td id=\"T_cce50_row0_col5\" class=\"data row0 col5\" >-0.662452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cce50_level0_row1\" class=\"row_heading level0 row1\" >feature_2</th>\n",
              "      <td id=\"T_cce50_row1_col0\" class=\"data row1 col0\" >0.088525</td>\n",
              "      <td id=\"T_cce50_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
              "      <td id=\"T_cce50_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
              "      <td id=\"T_cce50_row1_col3\" class=\"data row1 col3\" >0.254715</td>\n",
              "      <td id=\"T_cce50_row1_col4\" class=\"data row1 col4\" >-0.017930</td>\n",
              "      <td id=\"T_cce50_row1_col5\" class=\"data row1 col5\" >0.012852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cce50_level0_row2\" class=\"row_heading level0 row2\" >feature_3</th>\n",
              "      <td id=\"T_cce50_row2_col0\" class=\"data row2 col0\" >0.088525</td>\n",
              "      <td id=\"T_cce50_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
              "      <td id=\"T_cce50_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
              "      <td id=\"T_cce50_row2_col3\" class=\"data row2 col3\" >0.254715</td>\n",
              "      <td id=\"T_cce50_row2_col4\" class=\"data row2 col4\" >-0.017930</td>\n",
              "      <td id=\"T_cce50_row2_col5\" class=\"data row2 col5\" >0.012852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cce50_level0_row3\" class=\"row_heading level0 row3\" >feature_4</th>\n",
              "      <td id=\"T_cce50_row3_col0\" class=\"data row3 col0\" >0.985768</td>\n",
              "      <td id=\"T_cce50_row3_col1\" class=\"data row3 col1\" >0.254715</td>\n",
              "      <td id=\"T_cce50_row3_col2\" class=\"data row3 col2\" >0.254715</td>\n",
              "      <td id=\"T_cce50_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_cce50_row3_col4\" class=\"data row3 col4\" >-0.005849</td>\n",
              "      <td id=\"T_cce50_row3_col5\" class=\"data row3 col5\" >-0.640958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cce50_level0_row4\" class=\"row_heading level0 row4\" >feature_5</th>\n",
              "      <td id=\"T_cce50_row4_col0\" class=\"data row4 col0\" >-0.002907</td>\n",
              "      <td id=\"T_cce50_row4_col1\" class=\"data row4 col1\" >-0.017930</td>\n",
              "      <td id=\"T_cce50_row4_col2\" class=\"data row4 col2\" >-0.017930</td>\n",
              "      <td id=\"T_cce50_row4_col3\" class=\"data row4 col3\" >-0.005849</td>\n",
              "      <td id=\"T_cce50_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
              "      <td id=\"T_cce50_row4_col5\" class=\"data row4 col5\" >0.004133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cce50_level0_row5\" class=\"row_heading level0 row5\" >target</th>\n",
              "      <td id=\"T_cce50_row5_col0\" class=\"data row5 col0\" >-0.662452</td>\n",
              "      <td id=\"T_cce50_row5_col1\" class=\"data row5 col1\" >0.012852</td>\n",
              "      <td id=\"T_cce50_row5_col2\" class=\"data row5 col2\" >0.012852</td>\n",
              "      <td id=\"T_cce50_row5_col3\" class=\"data row5 col3\" >-0.640958</td>\n",
              "      <td id=\"T_cce50_row5_col4\" class=\"data row5 col4\" >0.004133</td>\n",
              "      <td id=\"T_cce50_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao analisar os valores de correlação entre as variáveis, identificamos que há uma forte correlação entre a feature 1 e a feature 4, assim como entre a feature 2 e a feature 3. Essa alta correlação indica que essas variáveis estão fornecendo informações muito semelhantes, portanto, optamos por remover uma dessas features (4 e 3) para evitar a duplicação de informações.\n",
        "\n",
        "Além disso, ao considerar a relevância das features em relação ao objetivo (target) da análise, observamos que a feature 5 tem um impacto relativamente baixo ou insignificante no resultado final. Assim, decidimos também remover a feature 5 para simplificar o modelo e focar nas variáveis mais influentes para a predição ou análise em questão.\n",
        "\n",
        "Embora este dataset seja pequeno, contendo apenas cinco features, na maioria dos casos lidamos com conjuntos de dados muito maiores, o que torna trabalhoso analisar cada feature individualmente. Nesse contexto, é vantajoso desenvolver um script para automatizar essa tarefa: por exemplo, remover as features que possuem um índice de correlação entre si superior a 0.9 e eliminar aquelas que apresentam uma correlação menor que 0.01 com a variável alvo target."
      ],
      "metadata": {
        "id": "35GfWE-HG8lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correlationSelection(df):\n",
        "  # Calcular a matriz de correlação\n",
        "  corr_matrix = df.corr()\n",
        "\n",
        "  # Identificar features com correlação maior que 0.9 entre si\n",
        "  high_corr_features = set()\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "      for j in range(i):\n",
        "          if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
        "              feature_name = corr_matrix.columns[i]\n",
        "              high_corr_features.add(feature_name)\n",
        "\n",
        "  #print(f'\\n-> features com alta correlação entre si: {high_corr_features}')\n",
        "\n",
        "  # Remover as features com alta correlação entre si\n",
        "  df.drop(high_corr_features, axis=1, inplace=True)\n",
        "  corr_matrix = df.corr()\n",
        "\n",
        "  # Identificar features com correlação abaixo de 0.01 com target\n",
        "  low_corr_with_target = []\n",
        "  for col in corr_matrix.columns:\n",
        "      if col != 'target' and abs(corr_matrix[col]['target']) < 0.01:\n",
        "          low_corr_with_target.append(col)\n",
        "\n",
        "  #print(f'-> features com baixa correlação com target: {low_corr_with_target}')\n",
        "\n",
        "  # Remover as features com baixa correlação com target\n",
        "  df.drop(low_corr_with_target, axis=1, inplace=True)\n",
        "\n",
        "  print(', '.join(df.columns))\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "df1 = pd.read_csv('/content/ia_fe_dataset1.csv')\n",
        "df2 = pd.read_csv('/content/ia_fe_dataset2.csv')\n",
        "df3 = pd.read_csv('/content/ia_fe_dataset3.csv')\n",
        "\n",
        "print('\\nDF1: ')\n",
        "df1_correlationSelection = correlationSelection(df1)\n",
        "print('\\nDF2: ')\n",
        "df2_correlationSelection = correlationSelection(df2)\n",
        "print('\\nDF3: ')\n",
        "df3_correlationSelection = correlationSelection(df3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85nwjjRhIzRG",
        "outputId": "884610f6-2e68-46c8-f0c0-733c5a3ca527"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DF1: \n",
            "feature_1, feature_2, target\n",
            "\n",
            "DF2: \n",
            "feature_2, feature_3, feature_4, feature_6, feature_9, feature_12, feature_13, feature_15, feature_17, feature_25, feature_29, feature_30, feature_32, feature_34, feature_39, feature_46, feature_49, target\n",
            "\n",
            "DF3: \n",
            "feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_8, feature_9, feature_10, feature_11, feature_13, feature_14, feature_15, feature_16, feature_18, feature_19, feature_20, feature_21, feature_22, feature_23, feature_24, feature_25, feature_26, feature_27, feature_28, feature_31, feature_32, feature_35, feature_36, feature_38, feature_39, feature_40, feature_41, feature_43, feature_44, feature_49, feature_52, feature_54, feature_55, feature_56, feature_57, feature_60, feature_62, feature_63, feature_64, feature_65, feature_70, feature_75, feature_78, feature_80, feature_81, feature_85, feature_88, feature_89, feature_92, feature_93, feature_94, feature_98, feature_99, target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao eliminar features redundantes e de baixa relevância, conseguimos simplificar o conjunto de dados e concentrar a atenção nas variáveis que têm um impacto mais significativo na predição ou análise dos resultados desejados. Essa abordagem de seleção de features é fundamental para garantir a precisão e a interpretabilidade dos modelos de análise de dados em diferentes contextos."
      ],
      "metadata": {
        "id": "Uuz58zg61ZJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select From Model\n",
        "Documentation: https://scikit-learn.org/stable/modules/feature_selection.html#select-from-model\n",
        "Reference guide: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
        "Source: https://github.com/scikit-learn/scikit-learn/blob/872124551/sklearn/feature_selection/_from_model.py#L93\n"
      ],
      "metadata": {
        "id": "3x4UVSf_qUHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# documentation: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
        "# source https://github.com/scikit-learn/scikit-learn/blob/872124551/sklearn/feature_selection/_from_model.py#L93\n",
        "\n",
        "\n",
        "def selectFromModel(df):\n",
        "  x = df.drop(columns=['target'])\n",
        "  y = df['target']\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  clf.fit(x, y)\n",
        "\n",
        "  sfm = SelectFromModel(clf, prefit=True)\n",
        "  selected_features = sfm.get_support()\n",
        "\n",
        "  selected_features = x.columns[selected_features]\n",
        "  print(', '.join(selected_features))\n",
        "\n",
        "  df = df[list(selected_features) + ['target'] ]\n",
        "  return df\n",
        "\n",
        "\n",
        "df1 = pd.read_csv('/content/ia_fe_dataset1.csv')\n",
        "\n",
        "print('\\nDF1: ')\n",
        "df1_selectFromModel = selectFromModel(df1)\n",
        "print('\\nDF2: ')\n",
        "df2_selectFromModel = selectFromModel(df2_correlationSelection)\n",
        "print('\\nDF3: ')\n",
        "df3_selectFromModel = selectFromModel(df3_correlationSelection)"
      ],
      "metadata": {
        "id": "3CGMDBlAr5lC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7397e96c-60b0-4cd4-f465-cbea46ccf17e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DF1: \n",
            "feature_1, feature_4\n",
            "\n",
            "DF2: \n",
            "feature_3, feature_9, feature_13, feature_15, feature_17, feature_30, feature_39\n",
            "\n",
            "DF3: \n",
            "feature_9, feature_10, feature_13, feature_14, feature_19, feature_20, feature_24, feature_27, feature_39, feature_40, feature_43, feature_49, feature_62, feature_63, feature_65, feature_85, feature_88, feature_98, feature_99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O SelectFromModel é uma técnica de seleção de atributos que utiliza um modelo de aprendizado de máquina para identificar os atributos mais importantes. Ele seleciona os atributos com base em sua importância calculada pelo modelo durante o treinamento.\n",
        "\n",
        "No caso específico do primeiro dataset as escolhas da 'feature_1' e 'feature_4', foi provavelmente porque possuem as maiores correlação com a variável alvo (target) e também por sua correlação forte entre si. Essas características indicam para o modelo que essas features são relevantes para a predição e podem conter informações úteis para o modelo. Entretanto, as colunas escolhidas são muito parecidas entre si, indicando que possívelmente são dados redundantes.\n",
        "\n",
        "Nos outros dois conjuntos de dados, observa-se uma redução no número de features selecionadas: foram escolhidas 7 (em comparação com as 17 do exercício anterior) e 19 em vez de 60 no terceiro conjunto. Essa redução é interessante porque pode simplificar o modelo, tornando-o mais fácil de interpretar e reduzindo a complexidade computacional.\n",
        "\n",
        "Portanto, pode ser benéfico considerar a combinação dessas duas técnicas de seleção de features. Inicialmente, realizar uma seleção inicial usando o Correlation Selection para identificar features altamente correlacionadas com a variável alvo. Em seguida, aplicar o Select From Model para refinar a seleção com base na importância das features para o modelo."
      ],
      "metadata": {
        "id": "Kulk6JMQ6_JK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recursive Feature Elimination\n",
        "### Documentation: https://scikit-learn.org/stable/modules/feature_selection.html#rfe\n",
        "### Reference guide: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
        "### Source: https://github.com/scikit-learn/scikit-learn/blob/872124551/sklearn/feature_selection/_rfe.py#L68"
      ],
      "metadata": {
        "id": "VrM8VEz9qnHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# documentation: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
        "# source: https://github.com/scikit-learn/scikit-learn/blob/872124551/sklearn/feature_selection/_rfe.py#L68\n",
        "\n",
        "def recursiveFeatureElimination(df, n):\n",
        "  x = df.drop(columns=['target'])\n",
        "  y = df['target']\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  rfe = RFE(estimator=clf, n_features_to_select=n, step=1)\n",
        "  rfe.fit(x, y)\n",
        "  selected_features = rfe.get_support()\n",
        "\n",
        "  selected_features = x.columns[selected_features]\n",
        "  print(', '.join(selected_features))\n",
        "\n",
        "  df = df[list(selected_features) + ['target'] ]\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "df1 = pd.read_csv('/content/ia_fe_dataset1.csv')\n",
        "\n",
        "print('\\nDF1: ')\n",
        "df1_recursiveFeatureElimination = recursiveFeatureElimination(df1, 2)\n",
        "print('\\nDF2: ')\n",
        "df2_recursiveFeatureElimination = recursiveFeatureElimination(df2_correlationSelection, 4)\n",
        "print('\\nDF3: ')\n",
        "df3_recursiveFeatureElimination = recursiveFeatureElimination(df3_correlationSelection, 9)"
      ],
      "metadata": {
        "id": "Y035HDl-uRGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ccd0bf-dc2b-4caa-a655-25a75cd327e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DF1: \n",
            "feature_1, feature_4\n",
            "\n",
            "DF2: \n",
            "feature_3, feature_13, feature_15, feature_39\n",
            "\n",
            "DF3: \n",
            "feature_19, feature_20, feature_24, feature_27, feature_39, feature_49, feature_85, feature_88, feature_98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Recursive Feature Elimination é geralmente considerada uma técnica robusta, pois avalia a importância das características iterativamente e elimina aquelas que contribuem menos para o desempenho do modelo. Nesse modelo é possível escolher o número de features como parâmetro, entretanto este número depende muito do seu conjunto de dados específico, da complexidade do problema que está tentando resolver e do desempenho desejado do modelo.\n",
        "\n",
        "Como o tempo de execução desse algoritmo é bem maior em relação aos outros escolhi executar para um número menor de features (4 para o segundo e 9 para o terceiro dataset).\n"
      ],
      "metadata": {
        "id": "PejPs4EbM3mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Feature Selection\n",
        "\n",
        "### documentation: https://scikit-learn.org/stable/modules/feature_selection.html#sequential-feature-selection\n",
        "### reference guide: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html\n",
        "### source: https://github.com/scikit-learn/scikit-learn/blob/872124551/sklearn/feature_selection/_sequential.py#L18"
      ],
      "metadata": {
        "id": "08vr6kzfrIJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "# documentation: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html\n",
        "# source: https://github.com/scikit-learn/scikit-learn/blob/872124551/sklearn/feature_selection/_sequential.py#L18\n",
        "\n",
        "\n",
        "df1 = pd.read_csv('/content/ia_fe_dataset1.csv')\n",
        "\n",
        "def sequentialFeatureSelection(df, n):\n",
        "  x = df.drop(columns=['target'])\n",
        "  y = df['target']\n",
        "\n",
        "  clf = RandomForestClassifier(n_estimators=100)\n",
        "  sfs = SFS(clf, n_features_to_select=n)\n",
        "  sfs = sfs.fit(x, y)\n",
        "\n",
        "  selected_features = sfs.get_support()\n",
        "  selected_features = x.columns[selected_features]\n",
        "  print(', '.join(selected_features))\n",
        "\n",
        "  df = df[list(selected_features) + ['target'] ]\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "df1 = pd.read_csv('/content/ia_fe_dataset1.csv')\n",
        "\n",
        "print('\\nDF1: ')\n",
        "df1_sequentialFeatureSelection = sequentialFeatureSelection(df1, 2)\n",
        "print('\\nDF2: ')\n",
        "df2_sequentialFeatureSelection = sequentialFeatureSelection(df2_correlationSelection, 3)\n",
        "print('\\nDF3: ')\n",
        "df3_sequentialFeatureSelection = sequentialFeatureSelection(df3_correlationSelection, 4)"
      ],
      "metadata": {
        "id": "ZtWNtZFhR7LX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73377046-9c7c-435c-cf44-ca0c56e4bee6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DF1: \n",
            "feature_1, feature_2\n",
            "\n",
            "DF2: \n",
            "feature_2, feature_3, feature_39\n",
            "\n",
            "DF3: \n",
            "feature_4, feature_20, feature_24, feature_85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Sequential Feature Selection é um método de seleção de features que funciona de forma iterativa, adicionando ou removendo features do modelo em cada iteração com o objetivo de encontrar o conjunto ótimo de features que maximize o desempenho do modelo. A desvantagem é que ele é computacionalmente intensivo então por isso tive que escolher um número menor ainda de features: 3 e 4 para o segundo e terceiro dataset respectivamente. Ainda assim a execução foi bem lenta."
      ],
      "metadata": {
        "id": "LPDIPLQxSkvH"
      }
    }
  ]
}